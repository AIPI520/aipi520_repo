{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch In-Class Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pytorch and torchvision if you have not already done so\n",
    "# pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data=load_breast_cancer(as_frame=True)\n",
    "X,y=data.data,data.target\n",
    "# Since the default in the file is 0=malignant 1=benign we want to reverse these\n",
    "y=(y==0).astype(int)\n",
    "X,y= np.array(X),np.array(y)\n",
    "\n",
    "# Let's set aside a test set and use the remainder for training and cross-validation\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.2)\n",
    "\n",
    "# Let's scale our data to help the algorithm converge faster\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaline from Scratch\n",
    "Below is an implementation of Adaline using only Python and NumPy.  For simplicity it does not include the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    \n",
    "    def __init__(self,eta=0.01,n_iter=100,random_state=0):\n",
    "        self.eta=eta\n",
    "        self.n_iter=n_iter\n",
    "        self.random_state=random_state\n",
    "        self.cost_path=[]\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        # Initialize the weights and bias (weights[0]) to small random numbers\n",
    "        rgen=np.random.RandomState(self.random_state)\n",
    "        self.weights = rgen.normal(loc=0.0,scale=0.01,size=(X.shape[1]))\n",
    "        \n",
    "        # Train adaline using batch gradient descent\n",
    "        for i in range(self.n_iter):\n",
    "            yhat = self.predict(X)\n",
    "            # Calculate the cost function\n",
    "            cost = np.sum(0.5 * (y-yhat)**2)\n",
    "            # Gradient of cost with respect to weights\n",
    "            gradient_weights = (y-yhat).T.dot(-X)\n",
    "            # Update weights\n",
    "            delta_weights = self.eta * gradient_weights\n",
    "            self.weights -= delta_weights\n",
    "            # Add cost to total cost counter\n",
    "            self.cost_path.append(cost)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        z = np.dot(X,self.weights)\n",
    "        yhat = 1*z\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Adaline from scratch\n",
    "adaline_model = Adaline(eta=0.0001,n_iter=100)\n",
    "adaline_model.fit(X_train_scaled,y_train)\n",
    "plt.plot(range(len(adaline_model.cost_path)),adaline_model.cost_path)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaline using Autograd\n",
    "Complete the methods of the class `Adaline_torch` below to train the model and generate predictions.  This implementation should use PyTorch and its autograd functionality rather than manually calculating the gradient of the cost function.  You do not need to include the bias term in this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline_torch:\n",
    "    \n",
    "    def __init__(self,eta=0.01,n_iter=100,random_state=0):\n",
    "        self.eta=eta\n",
    "        self.n_iter=n_iter\n",
    "        self.random_state=random_state\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        P = X.shape[1] # Number of features\n",
    "        # Initialize the weights to small random numbers and be sure to set requires_grad=True\n",
    "        self.weights = torch.rand(P,requires_grad=True)\n",
    "        \n",
    "        # Train adaline using batch gradient descent\n",
    "        self.cost_path=[]\n",
    "        for i in range(self.n_iter):\n",
    "            # Zero out the weights gradient each iteration\n",
    "            if self.weights.grad is not None:\n",
    "                self.weights.grad.zero_()\n",
    "            \n",
    "            ### BEGIN SOLUTION ###\n",
    "            raise NotImplementedError\n",
    "\n",
    "            ### END SOLUTION ###\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        ### BEGIN SOLUTION ###\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        ### END SOLUTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to tensors\n",
    "X_train_scaled_tensor = torch.from_numpy(X_train_scaled).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "adaline_model = Adaline_torch(eta=0.0001,n_iter=100)\n",
    "adaline_model.fit(X_train_scaled_tensor,y_train_tensor)\n",
    "plt.plot(range(len(adaline_model.cost_path)),adaline_model.cost_path)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipi520_fall24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
